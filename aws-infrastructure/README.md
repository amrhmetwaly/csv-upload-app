# AWS Infrastructure

This directory contains the AWS infrastructure components for the CSV Upload Application, built using AWS SAM (Serverless Application Model) and CloudFormation.

## ğŸ—ï¸ Architecture Overview

The application deploys a serverless architecture on AWS consisting of:

- **API Gateway**: RESTful API endpoint for CSV file uploads
- **Lambda Function**: Node.js 20.x runtime for processing CSV files
- **S3 Bucket**: Secure storage for uploaded CSV files
- **DynamoDB**: NoSQL database for storing file metadata and processing results
- **CloudWatch**: Logging and monitoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â–¶â”‚   API Gateway    â”‚â”€â”€â”€â–¶â”‚   Lambda        â”‚
â”‚   (Next.js)     â”‚    â”‚                  â”‚    â”‚   Function      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚   CloudWatch    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚   Logs          â”‚              â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                         â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚   S3 Bucket     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚   (CSV Storage) â”‚              â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                         â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚   DynamoDB      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚   (Metadata)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Directory Structure

```
aws-infrastructure/
â”œâ”€â”€ cloudformation/
â”‚   â”œâ”€â”€ template.yaml          # SAM CloudFormation template
â”‚   â””â”€â”€ samconfig.toml         # SAM configuration file
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Lambda handler function
â”‚   â”‚   â”œâ”€â”€ awsServices.ts    # AWS SDK service wrappers
â”‚   â”‚   â””â”€â”€ types.ts          # TypeScript type definitions
â”‚   â”œâ”€â”€ __tests__/            # Jest test files
â”‚   â”œâ”€â”€ package.json          # Lambda dependencies
â”‚   â””â”€â”€ tsconfig.json         # TypeScript configuration
â”œâ”€â”€ deployment/
â”‚   â””â”€â”€ lambda-function.zip   # Built Lambda deployment package
â”œâ”€â”€ deployment-info.json      # Current deployment information
â”œâ”€â”€ get-endpoint.sh          # Script to retrieve API endpoints
â””â”€â”€ README.md               # This file
```

## ğŸš€ Deployment

### Prerequisites

- AWS CLI configured with appropriate permissions
- AWS SAM CLI installed
- Node.js 20+ and npm

### Quick Deploy

1. **Deploy from project root:**
   ```bash
   ./scripts/deploy-aws.sh
   ```

2. **Get API endpoints:**
   ```bash
   cd aws-infrastructure
   ./get-endpoint.sh
   ```

3. **Update frontend configuration:**
   ```bash
   cd ..
   node scripts/update-frontend.js
   ```

### Manual Deployment Steps

1. **Build the Lambda function:**
   ```bash
   cd lambda
   npm install
   npm run build
   npm run package
   ```

2. **Deploy with SAM:**
   ```bash
   cd cloudformation
   sam deploy
   ```

3. **Retrieve endpoints:**
   ```bash
   cd ..
   ./get-endpoint.sh
   ```

## ğŸ”§ Configuration

### Environment Variables

The Lambda function uses these environment variables (automatically set by CloudFormation):

- `DYNAMODB_TABLE_NAME`: DynamoDB table for metadata storage
- `S3_BUCKET_NAME`: S3 bucket for CSV file storage
- `NODE_ENV`: Environment (dev/staging/prod)

### SAM Configuration (`samconfig.toml`)

```toml
stack_name = "csv-analyzer"
region = "us-west-2"
capabilities = "CAPABILITY_IAM"
parameter_overrides = "Environment=\"dev\" CorsOrigin=\"*\""
```

### CloudFormation Parameters

- `Environment`: Deployment environment (dev/staging/prod)
- `CorsOrigin`: CORS origin for API Gateway (default: "*")

## ğŸ“Š AWS Resources Created

### S3 Bucket
- **Name**: `csv-upload-{environment}-{account-id}`
- **Encryption**: AES256
- **Lifecycle**: Files deleted after 30 days
- **Access**: Private (no public access)

### DynamoDB Table
- **Name**: `csv-uploads-{environment}`
- **Billing**: Pay-per-request
- **Primary Key**: `id` (String)
- **GSI**: `UploadedAtIndex` on `uploadedAt`
- **Features**: Point-in-time recovery enabled

### Lambda Function
- **Name**: `csv-processor-{environment}`
- **Runtime**: Node.js 20.x
- **Memory**: 512 MB
- **Timeout**: 30 seconds
- **Handler**: `dist/index.handler`

### API Gateway
- **Type**: REST API
- **Endpoint**: `/energy/upload` (POST)
- **CORS**: Enabled for cross-origin requests
- **Integration**: Lambda proxy integration

## ğŸ§ª Testing

### Lambda Function Tests

```bash
cd lambda
npm test                    # Run all tests
npm run test:watch         # Watch mode
npm run test:coverage      # Coverage report
```

### Integration Testing

```bash
# From project root
node scripts/test-aws-endpoint.js
node scripts/check-aws-data.js
```

## ğŸ“ API Usage

### Upload Endpoint

**POST** `/energy/upload`

**Content-Type**: `multipart/form-data`

**Form Fields**:
- `file`: CSV file (required)
- `threshold`: Usage threshold in kWh (required)

**Example Response**:
```json
{
  "message": "CSV file processed successfully!",
  "data": {
    "fileName": "energy-usage.csv",
    "fileSize": "2.3 KB",
    "uploadedAt": "2024-01-15T10:30:00.000Z",
    "s3Key": "uploads/energy-usage-12345.csv",
    "dynamoDbId": "uuid-string",
    "processedRows": 100,
    "highUsageCount": 15,
    "statistics": {
      "mean": 250.5,
      "median": 230.0,
      "max": 450.2,
      "min": 120.1
    }
  }
}
```

## ğŸ” Monitoring

### CloudWatch Logs

- **Log Group**: `/aws/lambda/csv-processor-{environment}`
- **Retention**: 14 days
- **Access**: AWS Console â†’ CloudWatch â†’ Log Groups

### DynamoDB Monitoring

- **Metrics**: Read/Write capacity units, throttles, errors
- **Access**: AWS Console â†’ DynamoDB â†’ Tables â†’ Monitoring

### S3 Monitoring

- **Metrics**: Storage usage, requests, data retrieval
- **Access**: AWS Console â†’ S3 â†’ Metrics

## ğŸ› ï¸ Development

### Local Development

The Lambda function shares utilities with the frontend application:

```typescript
// Shared utilities from main application
const { CSVProcessingEngine } = require('../../../src/utils/csvProcessor');
const { FileValidator, ThresholdValidator } = require('../../../src/utils/validation');
```

### Building and Packaging

```bash
cd lambda
npm run build      # Compile TypeScript
npm run package    # Create deployment zip
```

## ğŸ”’ Security

- **S3 Bucket**: Private access only, server-side encryption enabled
- **DynamoDB**: Point-in-time recovery, encryption at rest
- **Lambda**: Minimal IAM permissions (read/write to specific resources only)
- **API Gateway**: CORS configured, no authentication (as per requirements)

## ğŸ§¹ Cleanup

To remove all AWS resources:

```bash
aws cloudformation delete-stack --stack-name csv-analyzer
```

## ğŸ“š Additional Resources

- [AWS SAM Documentation](https://docs.aws.amazon.com/serverless-application-model/)
- [Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- [S3 Security Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html) 